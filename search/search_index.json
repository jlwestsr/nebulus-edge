{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ai_project","text":"<p>Welcome to the documentation for ai_project.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Please refer to the README for installation and usage instructions.</p>"},{"location":"#features","title":"Features","text":"<p>Explore the features of this project:</p> <ul> <li>Feature Overview (if generated)</li> </ul>"},{"location":"AI_INSIGHTS/","title":"Project AI Insights (Long-Term Memory)","text":""},{"location":"AI_INSIGHTS/#purpose","title":"Purpose","text":"<p>This document serves as the Long-Term Memory for AI agents working on Nebulus Edge. It captures project-specific behavioral nuances, recurring pitfalls, and architectural decisions that are not strictly \"rules\" (in <code>AI_DIRECTIVES.md</code>) but are critical for maintaining continuity.</p>"},{"location":"AI_INSIGHTS/#1-architectural-patterns","title":"1. Architectural Patterns","text":"<ul> <li>Artifacts: Always update <code>task.md</code> before tool calls when starting a new phase.</li> <li>Three-service architecture: Brain (LLM, port 8080), Intelligence (data analytics, port 8081), Body (Open WebUI, port 3000). All PM2-managed services are defined in <code>infrastructure/pm2_config.json</code>.</li> <li>Intelligence service: FastAPI server at <code>intelligence/server.py</code>, started via <code>python -m intelligence.server</code>. Uses <code>intelligence/storage/</code> for runtime data (databases, vectors, knowledge, feedback) \u2014 this directory is gitignored.</li> </ul>"},{"location":"AI_INSIGHTS/#2-recurring-pitfalls","title":"2. Recurring Pitfalls","text":"<ul> <li>Testing: Do not assume tests pass; always checking logs.</li> <li>Dependencies: Three levels of requirements \u2014 <code>requirements.txt</code> (shared runtime), <code>brain/requirements.txt</code> and <code>intelligence/requirements.txt</code> (service-specific, used by their <code>start_*.sh</code> scripts), <code>requirements-dev.txt</code> (dev tooling: pytest, flake8, black, ansible). Check all before adding new libraries.</li> <li>pyproject.toml pythonpath: Must include both <code>\"src\"</code> and <code>\".\"</code> \u2014 the latter is required for <code>intelligence.*</code> imports to resolve in pytest.</li> <li>uvicorn reload: Intelligence server defaults <code>reload=False</code> for production (PM2). Set <code>INTELLIGENCE_RELOAD=true</code> env var for local dev only. Hardcoding <code>reload=True</code> causes issues under PM2.</li> <li>make down: Uses <code>pm2 stop all</code> to stop all services. If a new PM2 service is added, it will be stopped automatically \u2014 no Makefile change needed.</li> </ul>"},{"location":"AI_INSIGHTS/#3-workflow-nuances","title":"3. Workflow Nuances","text":"<ul> <li>Verification: Trust the test runner (<code>pytest</code> or <code>verify.yml</code>) over your assumptions.</li> <li>Start scripts: Both <code>start_brain.sh</code> and <code>start_intelligence.sh</code> auto-create the venv if missing. They install their own service-specific requirements on each start.</li> <li>Pre-commit hooks: The project runs end-of-file-fixer, black, flake8, and pytest as pre-commit hooks. If a commit fails on end-of-file-fixer, re-stage the modified files and create a new commit (do not amend).</li> </ul>"},{"location":"feature_template/","title":"Feature: [Feature Name]","text":""},{"location":"feature_template/#1-overview","title":"1. Overview","text":"<p>Branch: <code>feat/[feature-name]</code></p> <p>Briefly describe the feature, the problem it solves, and why it is being built.</p>"},{"location":"feature_template/#2-requirements","title":"2. Requirements","text":"<p>List specific, testable requirements: - [ ] Requirement 1 - [ ] Requirement 2</p>"},{"location":"feature_template/#3-technical-implementation","title":"3. Technical Implementation","text":"<ul> <li>Modules: List modified/created files (e.g., <code>src/module.py</code>).</li> <li>Dependencies: List new packages (e.g., <code>rich</code>).</li> <li>Data: Database changes or new assets.</li> </ul>"},{"location":"feature_template/#4-verification-plan","title":"4. Verification Plan","text":"<p>Automated Tests: - [ ] Script/Test: <code>pytest tests/test_feature.py</code> - [ ] Logic Verified: [Describe what is tested]</p> <p>Manual Verification: - [ ] Step 1: Run <code>forge --flag</code> - [ ] Step 2: Verify output in <code>dist/</code></p>"},{"location":"feature_template/#5-workflow-checklist","title":"5. Workflow Checklist","text":"<p>Follow the AI Behavior strict workflow: - [ ] Branch: Created <code>feat/...</code> branch? - [ ] Work: Implemented changes? - [ ] Test: All tests pass (<code>pytest</code>)? - [ ] Doc: Updated <code>README.md</code> and <code>walkthrough.md</code>? - [ ] Data: <code>git add .</code>, <code>git commit</code>, <code>git push</code>?</p>"},{"location":"features/body_layer_open_webui/","title":"Feature: Body Layer - Open WebUI","text":""},{"location":"features/body_layer_open_webui/#1-overview","title":"1. Overview","text":"<p>Branch: <code>feat/body-layer</code></p> <p>This feature implements the \"Body\" layer of the Nebulus Edge appliance using Open WebUI running in Docker. It provides a user-friendly chat interface for the local MLX \"Brain\" layer.</p>"},{"location":"features/body_layer_open_webui/#2-requirements","title":"2. Requirements","text":"<ul> <li>[ ] Provide Open WebUI interface via Docker.</li> <li>[ ] Accessible at <code>http://localhost:3000</code>.</li> <li>[ ] Connect to local Brain layer via <code>host-gateway</code>.</li> <li>[ ] Ensure compatibility with Brain API (OpenAI format).</li> <li>[ ] Automate deployment via Ansible.</li> </ul>"},{"location":"features/body_layer_open_webui/#3-technical-implementation","title":"3. Technical Implementation","text":"<ul> <li>Modules:</li> <li><code>body/docker-compose.yml</code> (New)</li> <li><code>infrastructure/start_body.sh</code> (New)</li> <li><code>brain/server.py</code> (Refactor for <code>/v1/chat/completions</code>)</li> <li><code>ansible/roles/body</code> (New)</li> <li><code>ansible/setup_nebulus.yml</code> (New playbook)</li> <li>Dependencies: Docker (System), <code>pydantic</code> (Python)</li> <li>Data: Docker volumes for Open WebUI persistence.</li> </ul>"},{"location":"features/body_layer_open_webui/#4-verification-plan","title":"4. Verification Plan","text":"<p>Automated Tests: - [ ] Ansible verification: <code>ansible-playbook ansible/setup_nebulus.yml</code> - [ ] Container check: <code>docker ps | grep open-webui</code></p> <p>Manual Verification: - [ ] Run <code>infrastructure/start_body.sh</code> - [ ] Browse <code>http://localhost:3000</code> - [ ] Create simple chat completion \"Hello World\"</p>"},{"location":"features/body_layer_open_webui/#5-workflow-checklist","title":"5. Workflow Checklist","text":"<p>Follow the AI Behavior strict workflow: - [ ] Branch: Created <code>feat/body-layer</code> branch? - [ ] Work: Implemented changes? - [ ] Test: All tests pass (<code>pytest</code> / connection check)? - [ ] Doc: Updated <code>README.md</code> and <code>walkthrough.md</code>? - [ ] Data: <code>git add .</code>, <code>git commit</code>, <code>git push</code>?</p>"},{"location":"features/persistence_layer/","title":"Feature: Persistence Layer (PM2 &amp; Makefile)","text":""},{"location":"features/persistence_layer/#1-overview","title":"1. Overview","text":"<p>Branch: <code>feat/persistence-layer</code></p> <p>This feature implements robust process management for the \"Brain\" layer using PM2 and standardizes build/run commands using a Makefile. This simplifies the developer workflow and ensures the Python backend runs reliably.</p>"},{"location":"features/persistence_layer/#2-requirements","title":"2. Requirements","text":"<ul> <li>[ ] Install <code>node</code> and <code>pm2</code> via Ansible (using local venv for execution).</li> <li>[ ] Configure PM2 to run the Brain layer (<code>nebulus-brain</code>).</li> <li>[ ] Create <code>Makefile</code> with <code>install</code>, <code>up</code>, and <code>down</code> targets.</li> <li>[ ] <code>make up</code> must start both Brain (PM2) and Body (Docker).</li> <li>[ ] <code>make down</code> must stop both.</li> </ul>"},{"location":"features/persistence_layer/#3-technical-implementation","title":"3. Technical Implementation","text":"<ul> <li>Modules:</li> <li><code>infrastructure/pm2_config.json</code> (New)</li> <li><code>Makefile</code> (New)</li> <li><code>requirements-dev.txt</code> (Update: add ansible)</li> <li><code>ansible/roles/persistence</code> (New)</li> <li><code>ansible/setup_nebulus.yml</code> (Update)</li> <li>Dependencies: Node.js, PM2, Ansible (venv verified)</li> <li>Data: PM2 logs (auto-managed).</li> </ul>"},{"location":"features/persistence_layer/#4-verification-plan","title":"4. Verification Plan","text":"<p>Automated Tests: - [ ] Ansible Playbook (Venv): <code>venv/bin/ansible-playbook ansible/setup_nebulus.yml</code> - [ ] Process Check: <code>pm2 status | grep nebulus-brain</code></p> <p>Manual Verification: - [ ] Run <code>make up</code> - verify endpoints. - [ ] Run <code>make down</code> - verify shutdown. - [ ] Verify Ansible installs PM2 globally.</p>"},{"location":"features/persistence_layer/#5-workflow-checklist","title":"5. Workflow Checklist","text":"<p>Follow the AI Behavior strict workflow: - [ ] Branch: Created <code>feat/persistence-layer</code> branch? - [ ] Work: Implemented changes? - [ ] Test: All tests pass? - [ ] Doc: Updated <code>README.md</code> and <code>walkthrough.md</code>? - [ ] Data: <code>git add .</code>, <code>git commit</code>, <code>git push</code>?</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/","title":"Multi-Source CSV Intelligence - Design Discussion","text":"<p>Date: 2026-02-02 Updated: 2026-02-02 Status: Customer feedback received - Hybrid approach selected MVP Feature: Multi-source data correlation with domain knowledge for inventory strategy</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#product-vision","title":"Product Vision","text":"<p>Nebulus Edge is a privacy-first AI appliance for small businesses handling sensitive data: - Target hardware: Mac mini (48GB RAM) - Target customers: Sales directors, doctors, lawyers, accountants - Key value: On-premise, turnkey, customer owns hardware - Business model: Sell configured hardware + software</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#initial-use-case-car-dealership-modern-motorcars","title":"Initial Use Case: Car Dealership (Modern Motorcars)","text":"<ul> <li>Sales director needs strategic inventory analysis, not just data queries</li> <li>Multiple data sources: inventory, service records, sales history, financing, warranties</li> <li>All sources share VIN as primary key</li> <li>Contains PII - must stay on-premise</li> <li>Primary Question: \"Based on historical sales, help me identify the ideal used vehicle inventory\"</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#customer-feedback-received","title":"Customer Feedback (Received)","text":""},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#q1-speed-accuracy-vs-flexibility","title":"Q1: Speed &amp; Accuracy vs. Flexibility?","text":"<p>Answer: \"Both equally - I need both capabilities\"</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#q2-hardest-question-youd-ask","title":"Q2: Hardest question you'd ask?","text":"<p>Answer: \"Based upon our historical sales, help me identify the ideal used vehicle inventory\" (Inventory Strategy)</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#domain-knowledge-requirements","title":"Domain Knowledge Requirements","text":"<p>The agent needs to understand variables that contribute to a \"perfect sale\" at Modern Motorcars: - Local buyer - Higher likelihood of service revenue, referrals - Trade-in - Margin opportunity, inventory acquisition - Financing - Dealer profit from financing arrangements - Warranty purchase - Additional revenue stream - Profit margins - Per-vehicle profitability - Age of inventory - Carrying costs, depreciation risk - Reconditioning spend - Investment vs. sale price delta</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#architecture-approaches-considered","title":"Architecture Approaches Considered","text":""},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#approach-1-sql-database-natural-language-to-sql","title":"Approach 1: SQL Database + Natural Language to SQL","text":"<p>Implementation: - User uploads CSVs \u2192 Import into SQLite database - VIN becomes foreign key linking tables - User asks question \u2192 LLM generates SQL \u2192 Execute \u2192 Return results + explanation</p> <p>Pros: - Dealership data is naturally tabular - SQL joins on VIN are what it's designed for - Deterministic results (critical for business decisions) - Can show generated SQL for transparency/trust - Fast execution even with large datasets</p> <p>Cons: - Requires schema management (can be automated) - SQL generation can fail on ambiguous questions - Cannot handle strategic/analytical questions like \"what's ideal inventory\"</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#approach-2-rag-based-vector-database","title":"Approach 2: RAG-based (Vector Database)","text":"<p>Implementation: - CSVs \u2192 Parse into vector embeddings (ChromaDB/FAISS) - VIN used for chunking/indexing - User asks \u2192 Semantic search finds relevant rows \u2192 LLM analyzes</p> <p>Pros: - More flexible for unstructured questions - Works well with current LLM setup - Can find patterns and similarities</p> <p>Cons: - Struggles with complex joins or exact filters - Less deterministic (business users may not trust it) - Slower for large datasets</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#approach-3-hybrid-sql-rag-domain-knowledge-selected","title":"Approach 3: Hybrid (SQL + RAG + Domain Knowledge) \u2b50 SELECTED","text":"<p>Implementation: - Structured data in SQLite for precise queries - Vector DB for semantic search and pattern matching - Domain Knowledge Layer for business rules and priorities - LLM orchestrates all three based on question type</p> <p>Pros: - Best of both worlds - precision AND flexibility - Can answer strategic questions requiring reasoning - Domain knowledge makes recommendations business-relevant - Transparent: can show SQL queries AND reasoning</p> <p>Cons: - Higher complexity (justified by requirements) - Three systems to maintain - Requires domain knowledge capture process</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#selected-architecture-hybrid-with-domain-knowledge","title":"Selected Architecture: Hybrid with Domain Knowledge","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      User Question                           \u2502\n\u2502  \"What's our ideal used vehicle inventory?\"                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 Question Classifier (LLM)                    \u2502\n\u2502  Determines: SQL query? Semantic search? Strategic analysis? \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                   \u25bc                   \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  SQL Engine     \u2502 \u2502 Semantic Search \u2502 \u2502 Domain Knowledge    \u2502\n\u2502  (SQLite)       \u2502 \u2502 (ChromaDB)      \u2502 \u2502 Layer               \u2502\n\u2502                 \u2502 \u2502                 \u2502 \u2502                     \u2502\n\u2502 - Exact queries \u2502 \u2502 - Similar sales \u2502 \u2502 - \"Perfect sale\"    \u2502\n\u2502 - Aggregations  \u2502 \u2502 - Patterns      \u2502 \u2502   variables         \u2502\n\u2502 - Joins on VIN  \u2502 \u2502 - Anomalies     \u2502 \u2502 - Business rules    \u2502\n\u2502 - Inventory age \u2502 \u2502 - Market comps  \u2502 \u2502 - Weights/priorities\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502                   \u2502                   \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  LLM Reasoning Layer                         \u2502\n\u2502  Synthesizes data + patterns + business rules into          \u2502\n\u2502  actionable strategic recommendations                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Response                                \u2502\n\u2502  \"Based on your sales data, ideal inventory characteristics: \u2502\n\u2502   - SUVs under $35k (67% of profitable sales)               \u2502\n\u2502   - &lt; 60 days old (avg margin 12% vs 4% after 90 days)      \u2502\n\u2502   - Local trade-ins (2.3x service revenue vs auction buys)  \u2502\n\u2502   [Show supporting data] [Show reasoning]\"                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#domain-knowledge-layer-design","title":"Domain Knowledge Layer Design","text":""},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#purpose","title":"Purpose","text":"<p>Capture the sales director's business expertise so the AI can reason about \"what's good\" not just \"what is.\"</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#knowledge-categories","title":"Knowledge Categories","text":"<p>1. Sale Quality Factors (weighted scoring) | Factor | Description | Weight | |--------|-------------|--------| | Local buyer | Customer within N miles | +15 | | Trade-in | Vehicle accepted as trade | +20 | | Financing | Dealer-arranged financing | +25 | | Warranty | Extended warranty sold | +15 | | Quick turn | Sold within 30 days | +10 | | Above-margin | Profit &gt; target margin | +15 |</p> <p>2. Inventory Health Metrics - Days on lot (target: &lt; 45 days) - Reconditioning ROI (spend vs. margin impact) - Category mix (SUV/Sedan/Truck ratios) - Price band distribution</p> <p>3. Business Rules - \"Never stock vehicles &gt; 100k miles\" - \"Prioritize trade-ins over auction\" - \"Target 15% gross margin on used\"</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#knowledge-capture-methods","title":"Knowledge Capture Methods","text":"<ol> <li>Structured interview - One-time setup conversation</li> <li>Document upload - Business rules, SOPs, pricing guides</li> <li>Feedback loop - \"This recommendation was good/bad\" learning</li> </ol>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#implementation-phases-revised","title":"Implementation Phases (Revised)","text":""},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#phase-1-foundation-mvp","title":"Phase 1: Foundation (MVP)","text":"<ul> <li>CSV upload interface in Open WebUI</li> <li>SQLite import with VIN auto-detection</li> <li>Basic natural language to SQL</li> <li>Query execution and result formatting</li> <li>Deliverable: Answer \"How many vehicles over 60 days on lot?\"</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#phase-2-domain-knowledge-layer","title":"Phase 2: Domain Knowledge Layer","text":"<ul> <li>Knowledge capture interface (structured Q&amp;A)</li> <li>Business rules storage (JSON/YAML)</li> <li>Sale quality scoring system</li> <li>Deliverable: Score historical sales by \"quality\"</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#phase-3-semantic-search","title":"Phase 3: Semantic Search","text":"<ul> <li>ChromaDB integration for vector storage</li> <li>Embed sales records for pattern matching</li> <li>Similar vehicle/sale finder</li> <li>Deliverable: \"Find sales similar to this successful one\"</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#phase-4-strategic-analysis","title":"Phase 4: Strategic Analysis","text":"<ul> <li>Question classifier (SQL vs semantic vs strategic)</li> <li>Multi-source reasoning</li> <li>Recommendation generation</li> <li>Deliverable: \"What's our ideal inventory?\" with reasoning</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#phase-5-security-privacy","title":"Phase 5: Security &amp; Privacy","text":"<ul> <li>PII detection and masking</li> <li>Data encryption at rest</li> <li>Audit logging</li> <li>Access controls</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#phase-6-continuous-learning","title":"Phase 6: Continuous Learning","text":"<ul> <li>Feedback capture on recommendations</li> <li>Knowledge refinement from outcomes</li> <li>Automated insight generation</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#technical-considerations","title":"Technical Considerations","text":""},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#current-stack","title":"Current Stack","text":"<ul> <li>Brain: FastAPI + MLX (Qwen3-Coder-30B)</li> <li>Body: Open WebUI (Docker)</li> <li>Infrastructure: PM2 + Ansible</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#additions-needed","title":"Additions Needed","text":"<p>Data Layer: - SQLite for structured data - ChromaDB for vector embeddings - JSON/YAML for domain knowledge</p> <p>Processing: - CSV parsing and validation - Schema inference - Text-to-SQL engine - Embedding generation - Query sandbox for safety</p> <p>New Components: - Question classifier - Domain knowledge manager - Multi-source orchestrator - Recommendation synthesizer</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#security-requirements","title":"Security Requirements","text":"<ul> <li>No data leaves the Mac mini</li> <li>Encryption at rest</li> <li>PII auto-detection</li> <li>Query result sanitization</li> <li>Audit trail</li> </ul>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#open-questions","title":"Open Questions","text":"<ol> <li>Knowledge capture UX - How does the sales director \"teach\" the system?</li> <li>Wizard-style interview?</li> <li>Upload existing documents?</li> <li> <p>Natural conversation?</p> </li> <li> <p>What data sources exist?</p> </li> <li>DMS exports (which system?)</li> <li>Manual spreadsheets?</li> <li> <p>Update frequency?</p> </li> <li> <p>How to validate recommendations?</p> </li> <li>Backtest against historical outcomes?</li> <li> <p>A/B test suggestions?</p> </li> <li> <p>\"Ideal\" definition - Is it:</p> </li> <li>Fastest turn rate?</li> <li>Highest margin?</li> <li>Balanced portfolio?</li> <li> <p>All of the above with weights?</p> </li> <li> <p>Schema conflicts - How to handle mismatched CSVs?</p> </li> <li> <p>Embedding model - Use Qwen for embeddings or separate model?</p> </li> </ol>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#success-criteria","title":"Success Criteria","text":"<p>For MVP (Phase 1): - Upload 3+ CSVs with VIN column - Ask natural language question requiring cross-source join - Get accurate results in &lt;5 seconds - Results are verifiable (show SQL) - No data leaves the box</p> <p>For Strategic Analysis (Phase 4): - Ask \"What's our ideal inventory?\" - Get actionable recommendations with reasoning - Recommendations align with captured business rules - Sales director trusts and uses insights weekly</p> <p>For Product: - Non-technical user can operate without training - Handles real-world messy CSV data - Passes security audit for PII handling - Sales director uses it daily for decisions</p>"},{"location":"plans/2026-02-02-multi-source-csv-intelligence/#related-nebulus-projects","title":"Related Nebulus Projects","text":"<ul> <li>Nebulus Prime: Linux version (server/datacenter)</li> <li>Nebulus Gantry: Custom web UI (Open WebUI fork)</li> <li>Nebulus Atom: AI agent system (Claude Desktop inspired)</li> </ul>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/","title":"Nebulus Intelligence - Architecture Sketch","text":"<p>Date: 2026-02-02 Status: Draft architecture sketch Purpose: Reusable data intelligence platform with vertical templates</p>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#overview","title":"Overview","text":"<p>Nebulus Intelligence is a new component that sits alongside Brain and Body, providing: - Multi-source data ingestion and storage - Domain knowledge management - Hybrid query engine (SQL + Semantic) - Strategic reasoning via Brain integration</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         User (Open WebUI)                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Body (Open WebUI)                           \u2502\n\u2502                   Port 3000 (Docker)                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u25bc                               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Brain             \u2502   \u2502        Intelligence           \u2502\n\u2502     (LLM Server)          \u2502   \u2502    (Data + Knowledge)         \u2502\n\u2502     Port 8080             \u2502   \u2502       Port 8081               \u2502\n\u2502                           \u2502   \u2502                               \u2502\n\u2502  - Chat completions       \u2502   \u2502  - Data ingestion             \u2502\n\u2502  - Model management       \u2502   \u2502  - Query execution            \u2502\n\u2502                           \u2502   \u2502  - Knowledge management       \u2502\n\u2502                           \u2502\u25c4\u2500\u2500\u2502  - Calls Brain for reasoning  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         MLX                              SQLite + ChromaDB\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#directory-structure","title":"Directory Structure","text":"<pre><code>nebulus-edge/\n\u251c\u2500\u2500 brain/                      # Existing LLM server\n\u251c\u2500\u2500 body/                       # Existing Open WebUI\n\u251c\u2500\u2500 intelligence/               # NEW\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 server.py               # FastAPI application\n\u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 core/                   # Core engine components\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 ingest.py           # CSV parsing, validation, import\n\u2502   \u2502   \u251c\u2500\u2500 sql_engine.py       # SQLite wrapper, text-to-SQL\n\u2502   \u2502   \u251c\u2500\u2500 vector_engine.py    # ChromaDB wrapper, embeddings\n\u2502   \u2502   \u251c\u2500\u2500 knowledge.py        # Domain knowledge manager\n\u2502   \u2502   \u251c\u2500\u2500 classifier.py       # Question type classification\n\u2502   \u2502   \u2514\u2500\u2500 orchestrator.py     # Routes queries to engines\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 templates/              # Vertical configurations\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 base.py             # Base template class\n\u2502   \u2502   \u251c\u2500\u2500 dealership/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 config.yaml     # Schema, rules, prompts\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 scoring.py      # Custom scoring logic\n\u2502   \u2502   \u251c\u2500\u2500 medical/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 config.yaml\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 scoring.py\n\u2502   \u2502   \u2514\u2500\u2500 legal/\n\u2502   \u2502       \u251c\u2500\u2500 config.yaml\n\u2502   \u2502       \u2514\u2500\u2500 scoring.py\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 api/                    # API routes\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 data.py             # Upload, list, delete datasets\n\u2502   \u2502   \u251c\u2500\u2500 query.py            # Ask questions\n\u2502   \u2502   \u251c\u2500\u2500 knowledge.py        # Manage domain knowledge\n\u2502   \u2502   \u2514\u2500\u2500 admin.py            # Template management, health\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 storage/                # Data persistence (gitignored)\n\u2502       \u251c\u2500\u2500 databases/          # SQLite files per customer\n\u2502       \u251c\u2500\u2500 vectors/            # ChromaDB collections\n\u2502       \u2514\u2500\u2500 knowledge/          # Domain knowledge JSON\n\u2502\n\u251c\u2500\u2500 infrastructure/\n\u2502   \u251c\u2500\u2500 pm2_config.json         # Add intelligence process\n\u2502   \u2514\u2500\u2500 start_intelligence.sh   # Startup script\n\u2502\n\u2514\u2500\u2500 tests/\n    \u2514\u2500\u2500 intelligence/           # Tests for new component\n        \u251c\u2500\u2500 test_ingest.py\n        \u251c\u2500\u2500 test_sql_engine.py\n        \u251c\u2500\u2500 test_orchestrator.py\n        \u2514\u2500\u2500 test_templates.py\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#core-components","title":"Core Components","text":""},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#1-ingest-coreingestpy","title":"1. Ingest (<code>core/ingest.py</code>)","text":"<p>Handles CSV upload, validation, and import into SQLite.</p> <pre><code>class DataIngestor:\n    \"\"\"CSV ingestion with schema inference and primary key detection.\"\"\"\n\n    def ingest_csv(\n        self,\n        file_path: str,\n        table_name: str,\n        template: str = \"generic\",\n        primary_key_hint: str | None = None\n    ) -&gt; IngestResult:\n        \"\"\"\n        1. Parse CSV, infer column types\n        2. Detect primary key (VIN, PatientID, CaseID based on template)\n        3. Create/update SQLite table\n        4. Generate embeddings for semantic search\n        5. Return schema and row count\n        \"\"\"\n        pass\n\n    def detect_primary_key(self, df: DataFrame, template: str) -&gt; str:\n        \"\"\"Auto-detect primary key based on template hints.\"\"\"\n        # Dealership: look for VIN, Stock#, StockNumber\n        # Medical: look for PatientID, MRN, Patient_ID\n        # Legal: look for CaseID, Case#, MatterID\n        pass\n\n    def infer_relationships(self, tables: list[str]) -&gt; list[Relationship]:\n        \"\"\"Find foreign key relationships across tables.\"\"\"\n        pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#2-sql-engine-coresql_enginepy","title":"2. SQL Engine (<code>core/sql_engine.py</code>)","text":"<p>Wraps SQLite with natural language to SQL conversion.</p> <pre><code>class SQLEngine:\n    \"\"\"Execute SQL queries with natural language interface.\"\"\"\n\n    def __init__(self, db_path: str, brain_url: str):\n        self.conn = sqlite3.connect(db_path)\n        self.brain_url = brain_url\n\n    def get_schema(self) -&gt; dict:\n        \"\"\"Return all tables, columns, types, relationships.\"\"\"\n        pass\n\n    def natural_to_sql(self, question: str, schema: dict) -&gt; str:\n        \"\"\"\n        Call Brain to convert natural language to SQL.\n        Include schema context in prompt.\n        \"\"\"\n        prompt = f\"\"\"Given this database schema:\n{schema}\n\nConvert this question to SQL:\n\"{question}\"\n\nReturn only valid SQLite SQL, no explanation.\"\"\"\n\n        response = self._call_brain(prompt)\n        return self._extract_sql(response)\n\n    def execute(self, sql: str, safe: bool = True) -&gt; QueryResult:\n        \"\"\"\n        Execute SQL with safety checks.\n        If safe=True, only allow SELECT statements.\n        \"\"\"\n        if safe and not sql.strip().upper().startswith(\"SELECT\"):\n            raise UnsafeQueryError(\"Only SELECT allowed\")\n\n        return self.conn.execute(sql).fetchall()\n\n    def explain_results(self, question: str, sql: str, results: list) -&gt; str:\n        \"\"\"Call Brain to explain query results in natural language.\"\"\"\n        pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#3-vector-engine-corevector_enginepy","title":"3. Vector Engine (<code>core/vector_engine.py</code>)","text":"<p>ChromaDB wrapper for semantic search.</p> <pre><code>class VectorEngine:\n    \"\"\"Semantic search over business data.\"\"\"\n\n    def __init__(self, collection_name: str):\n        self.client = chromadb.PersistentClient(path=\"./storage/vectors\")\n        self.collection = self.client.get_or_create_collection(collection_name)\n\n    def embed_records(self, records: list[dict], id_field: str):\n        \"\"\"\n        Convert records to embeddings and store.\n        Each record becomes a document with metadata.\n        \"\"\"\n        pass\n\n    def search_similar(\n        self,\n        query: str,\n        n_results: int = 10,\n        filters: dict | None = None\n    ) -&gt; list[SimilarRecord]:\n        \"\"\"Find records semantically similar to query.\"\"\"\n        pass\n\n    def find_patterns(self, positive_examples: list[str]) -&gt; PatternResult:\n        \"\"\"\n        Given IDs of 'good' records, find what they have in common.\n        Useful for \"what makes a good sale\" type questions.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#4-knowledge-manager-coreknowledgepy","title":"4. Knowledge Manager (<code>core/knowledge.py</code>)","text":"<p>Stores and retrieves domain expertise.</p> <pre><code>class KnowledgeManager:\n    \"\"\"Manage domain knowledge for a business.\"\"\"\n\n    def __init__(self, knowledge_path: str):\n        self.path = knowledge_path\n        self.knowledge = self._load()\n\n    def get_scoring_factors(self) -&gt; list[ScoringFactor]:\n        \"\"\"Return weighted factors for outcome scoring.\"\"\"\n        return self.knowledge.get(\"scoring_factors\", [])\n\n    def get_business_rules(self) -&gt; list[BusinessRule]:\n        \"\"\"Return business rules and constraints.\"\"\"\n        return self.knowledge.get(\"rules\", [])\n\n    def get_metrics(self) -&gt; list[MetricDefinition]:\n        \"\"\"Return metric definitions (targets, thresholds).\"\"\"\n        return self.knowledge.get(\"metrics\", [])\n\n    def add_knowledge(self, category: str, item: dict):\n        \"\"\"Add new knowledge from user teaching.\"\"\"\n        pass\n\n    def export_for_prompt(self) -&gt; str:\n        \"\"\"Format knowledge for LLM context injection.\"\"\"\n        return f\"\"\"\nBusiness Rules:\n{self._format_rules()}\n\nScoring Factors (what makes a good outcome):\n{self._format_scoring()}\n\nKey Metrics:\n{self._format_metrics()}\n\"\"\"\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#5-question-classifier-coreclassifierpy","title":"5. Question Classifier (<code>core/classifier.py</code>)","text":"<p>Routes questions to the right engine(s).</p> <pre><code>class QuestionClassifier:\n    \"\"\"Determine how to answer a question.\"\"\"\n\n    class QueryType(Enum):\n        SQL_ONLY = \"sql\"           # \"How many cars over 60 days?\"\n        SEMANTIC_ONLY = \"semantic\"  # \"Find sales like this one\"\n        STRATEGIC = \"strategic\"     # \"What's ideal inventory?\"\n        HYBRID = \"hybrid\"           # Needs multiple sources\n\n    def classify(self, question: str, schema: dict) -&gt; ClassificationResult:\n        \"\"\"\n        Analyze question and determine:\n        - Which engine(s) to use\n        - What data to retrieve\n        - Whether domain knowledge is needed\n        \"\"\"\n        # Call Brain with classification prompt\n        prompt = f\"\"\"Classify this business question:\n\"{question}\"\n\nAvailable data: {schema}\n\nIs this:\n1. SQL_ONLY - Can be answered with a database query (counts, filters, joins)\n2. SEMANTIC_ONLY - Needs similarity/pattern search\n3. STRATEGIC - Needs reasoning about \"what's best\" using business rules\n4. HYBRID - Needs multiple approaches combined\n\nReturn JSON: {{\"type\": \"...\", \"reasoning\": \"...\"}}\"\"\"\n\n        return self._parse_classification(self._call_brain(prompt))\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#6-orchestrator-coreorchestratorpy","title":"6. Orchestrator (<code>core/orchestrator.py</code>)","text":"<p>The main entry point that coordinates everything.</p> <pre><code>class IntelligenceOrchestrator:\n    \"\"\"Main query orchestrator - the brain of Intelligence.\"\"\"\n\n    def __init__(\n        self,\n        sql_engine: SQLEngine,\n        vector_engine: VectorEngine,\n        knowledge: KnowledgeManager,\n        classifier: QuestionClassifier,\n        brain_url: str,\n        template: str = \"generic\"\n    ):\n        self.sql = sql_engine\n        self.vectors = vector_engine\n        self.knowledge = knowledge\n        self.classifier = classifier\n        self.brain_url = brain_url\n        self.template = self._load_template(template)\n\n    async def ask(self, question: str) -&gt; IntelligenceResponse:\n        \"\"\"\n        Main entry point for all questions.\n\n        Returns:\n            IntelligenceResponse with:\n            - answer: Natural language response\n            - supporting_data: Tables, charts\n            - reasoning: How we got here\n            - sql_used: For transparency (if applicable)\n            - confidence: How sure we are\n        \"\"\"\n        # 1. Classify the question\n        classification = self.classifier.classify(question, self.sql.get_schema())\n\n        # 2. Gather data based on classification\n        context = await self._gather_context(question, classification)\n\n        # 3. If strategic, inject domain knowledge\n        if classification.type in [QueryType.STRATEGIC, QueryType.HYBRID]:\n            context[\"knowledge\"] = self.knowledge.export_for_prompt()\n\n        # 4. Call Brain for final synthesis\n        answer = await self._synthesize(question, context, classification)\n\n        return IntelligenceResponse(\n            answer=answer.text,\n            supporting_data=context.get(\"data\"),\n            reasoning=answer.reasoning,\n            sql_used=context.get(\"sql\"),\n            confidence=answer.confidence\n        )\n\n    async def _gather_context(\n        self,\n        question: str,\n        classification: ClassificationResult\n    ) -&gt; dict:\n        \"\"\"Gather relevant data from appropriate engines.\"\"\"\n        context = {}\n\n        if classification.needs_sql:\n            sql = self.sql.natural_to_sql(question, self.sql.get_schema())\n            results = self.sql.execute(sql)\n            context[\"sql\"] = sql\n            context[\"sql_results\"] = results\n\n        if classification.needs_semantic:\n            similar = self.vectors.search_similar(question)\n            context[\"similar_records\"] = similar\n\n        return context\n\n    async def _synthesize(\n        self,\n        question: str,\n        context: dict,\n        classification: ClassificationResult\n    ) -&gt; SynthesisResult:\n        \"\"\"Call Brain to synthesize final answer.\"\"\"\n        prompt = self._build_synthesis_prompt(question, context, classification)\n        response = await self._call_brain(prompt)\n        return self._parse_synthesis(response)\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#vertical-templates","title":"Vertical Templates","text":""},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#template-structure-templatesdealershipconfigyaml","title":"Template Structure (<code>templates/dealership/config.yaml</code>)","text":"<pre><code># Dealership Vertical Template\nname: dealership\ndisplay_name: \"Auto Dealership\"\nversion: \"1.0\"\n\n# Primary key detection hints\nprimary_keys:\n  - vin\n  - VIN\n  - stock_number\n  - StockNumber\n  - stock_no\n\n# Expected data sources\ndata_sources:\n  inventory:\n    description: \"Current vehicle inventory\"\n    required_columns:\n      - vin\n      - make\n      - model\n      - year\n      - asking_price\n    optional_columns:\n      - days_on_lot\n      - acquisition_cost\n      - reconditioning_cost\n\n  sales:\n    description: \"Historical sales records\"\n    required_columns:\n      - vin\n      - sale_date\n      - sale_price\n    optional_columns:\n      - buyer_zip\n      - trade_in\n      - financing\n      - warranty_sold\n      - gross_profit\n\n  service:\n    description: \"Service records\"\n    required_columns:\n      - vin\n      - service_date\n    optional_columns:\n      - service_type\n      - revenue\n      - customer_zip\n\n# Default scoring factors\nscoring:\n  perfect_sale:\n    local_buyer:\n      description: \"Buyer within 25 miles\"\n      weight: 15\n      calculation: \"buyer_zip proximity check\"\n    trade_in:\n      description: \"Trade-in accepted\"\n      weight: 20\n      calculation: \"trade_in IS NOT NULL\"\n    financing:\n      description: \"Dealer financing used\"\n      weight: 25\n      calculation: \"financing = true\"\n    warranty:\n      description: \"Extended warranty sold\"\n      weight: 15\n      calculation: \"warranty_sold = true\"\n    quick_turn:\n      description: \"Sold within 30 days\"\n      weight: 10\n      calculation: \"days_to_sale &lt;= 30\"\n    above_margin:\n      description: \"Above target margin\"\n      weight: 15\n      calculation: \"gross_profit / sale_price &gt; 0.15\"\n\n# Default business rules\nrules:\n  - name: \"max_mileage\"\n    description: \"Don't stock vehicles over 100k miles\"\n    condition: \"mileage &lt;= 100000\"\n  - name: \"max_age\"\n    description: \"Avoid vehicles older than 10 years\"\n    condition: \"year &gt;= CURRENT_YEAR - 10\"\n  - name: \"target_margin\"\n    description: \"Target 15% gross margin\"\n    value: 0.15\n\n# Default metrics\nmetrics:\n  days_on_lot:\n    target: 45\n    warning: 60\n    critical: 90\n  gross_margin:\n    target: 0.15\n    warning: 0.10\n    critical: 0.05\n  inventory_turn:\n    target: 12  # per year\n    warning: 8\n    critical: 6\n\n# Pre-built queries for this vertical\ncanned_queries:\n  - name: \"aged_inventory\"\n    question: \"Which vehicles have been on the lot over 60 days?\"\n    sql: \"SELECT * FROM inventory WHERE days_on_lot &gt; 60 ORDER BY days_on_lot DESC\"\n\n  - name: \"top_performers\"\n    question: \"What were our most profitable sales last month?\"\n    sql: &gt;\n      SELECT * FROM sales\n      WHERE sale_date &gt;= date('now', '-30 days')\n      ORDER BY gross_profit DESC LIMIT 10\n\n  - name: \"service_opportunities\"\n    question: \"Which sold vehicles haven't returned for service?\"\n    sql: &gt;\n      SELECT s.* FROM sales s\n      LEFT JOIN service sv ON s.vin = sv.vin\n      WHERE sv.vin IS NULL\n      AND s.sale_date &lt; date('now', '-90 days')\n\n# Prompts customized for this vertical\nprompts:\n  system: |\n    You are an AI assistant for an auto dealership. You help analyze\n    inventory, sales, and service data to make strategic business decisions.\n    Always consider factors like days on lot, gross margin, and customer lifetime value.\n\n  strategic_analysis: |\n    When analyzing \"ideal inventory\", consider:\n    1. Historical sales velocity by vehicle type\n    2. Gross margin by category\n    3. Customer demographics and preferences\n    4. Seasonal trends\n    5. Current inventory gaps\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#template-base-class-templatesbasepy","title":"Template Base Class (<code>templates/base.py</code>)","text":"<pre><code>from abc import ABC, abstractmethod\nfrom pathlib import Path\nimport yaml\n\nclass VerticalTemplate(ABC):\n    \"\"\"Base class for vertical templates.\"\"\"\n\n    def __init__(self, template_dir: Path):\n        self.config = self._load_config(template_dir / \"config.yaml\")\n        self.name = self.config[\"name\"]\n\n    def _load_config(self, path: Path) -&gt; dict:\n        with open(path) as f:\n            return yaml.safe_load(f)\n\n    def get_primary_key_hints(self) -&gt; list[str]:\n        \"\"\"Return column names that might be primary keys.\"\"\"\n        return self.config.get(\"primary_keys\", [])\n\n    def get_scoring_factors(self) -&gt; dict:\n        \"\"\"Return scoring configuration.\"\"\"\n        return self.config.get(\"scoring\", {})\n\n    def get_business_rules(self) -&gt; list[dict]:\n        \"\"\"Return business rules.\"\"\"\n        return self.config.get(\"rules\", [])\n\n    def get_metrics(self) -&gt; dict:\n        \"\"\"Return metric definitions.\"\"\"\n        return self.config.get(\"metrics\", {})\n\n    def get_system_prompt(self) -&gt; str:\n        \"\"\"Return customized system prompt.\"\"\"\n        return self.config.get(\"prompts\", {}).get(\"system\", \"\")\n\n    @abstractmethod\n    def calculate_score(self, record: dict) -&gt; float:\n        \"\"\"Calculate outcome score for a record. Override per vertical.\"\"\"\n        pass\n\n    @abstractmethod\n    def validate_data(self, table_name: str, df) -&gt; ValidationResult:\n        \"\"\"Validate uploaded data against template expectations.\"\"\"\n        pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#api-endpoints","title":"API Endpoints","text":""},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#apidatapy-data-management","title":"<code>api/data.py</code> - Data Management","text":"<pre><code>from fastapi import APIRouter, UploadFile, File, HTTPException\n\nrouter = APIRouter(prefix=\"/data\", tags=[\"data\"])\n\n@router.post(\"/upload\")\nasync def upload_csv(\n    file: UploadFile = File(...),\n    table_name: str = None,\n    template: str = \"generic\"\n) -&gt; IngestResult:\n    \"\"\"\n    Upload a CSV file for analysis.\n\n    - Auto-detects schema and primary key\n    - Creates SQLite table\n    - Generates embeddings for semantic search\n    \"\"\"\n    pass\n\n@router.get(\"/tables\")\nasync def list_tables() -&gt; list[TableInfo]:\n    \"\"\"List all uploaded data tables with schema info.\"\"\"\n    pass\n\n@router.get(\"/tables/{table_name}/schema\")\nasync def get_schema(table_name: str) -&gt; SchemaInfo:\n    \"\"\"Get detailed schema for a table.\"\"\"\n    pass\n\n@router.get(\"/tables/{table_name}/preview\")\nasync def preview_data(table_name: str, limit: int = 10) -&gt; list[dict]:\n    \"\"\"Preview rows from a table.\"\"\"\n    pass\n\n@router.delete(\"/tables/{table_name}\")\nasync def delete_table(table_name: str) -&gt; dict:\n    \"\"\"Delete a table and its embeddings.\"\"\"\n    pass\n\n@router.get(\"/relationships\")\nasync def get_relationships() -&gt; list[Relationship]:\n    \"\"\"Get detected relationships between tables.\"\"\"\n    pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#apiquerypy-query-interface","title":"<code>api/query.py</code> - Query Interface","text":"<pre><code>router = APIRouter(prefix=\"/query\", tags=[\"query\"])\n\n@router.post(\"/ask\")\nasync def ask_question(request: QuestionRequest) -&gt; IntelligenceResponse:\n    \"\"\"\n    Ask a natural language question about your data.\n\n    The system automatically:\n    1. Classifies the question type\n    2. Queries appropriate data sources\n    3. Applies domain knowledge if needed\n    4. Returns answer with supporting data\n    \"\"\"\n    return await orchestrator.ask(request.question)\n\n@router.post(\"/sql\")\nasync def execute_sql(request: SQLRequest) -&gt; SQLResponse:\n    \"\"\"\n    Execute raw SQL (for power users).\n    Only SELECT statements allowed.\n    \"\"\"\n    pass\n\n@router.post(\"/similar\")\nasync def find_similar(request: SimilarityRequest) -&gt; list[SimilarRecord]:\n    \"\"\"\n    Find records similar to a given example.\n\n    Use cases:\n    - \"Find sales like this one\"\n    - \"Find vehicles similar to VIN X\"\n    \"\"\"\n    pass\n\n@router.get(\"/canned\")\nasync def list_canned_queries() -&gt; list[CannedQuery]:\n    \"\"\"List pre-built queries for current template.\"\"\"\n    pass\n\n@router.post(\"/canned/{query_name}\")\nasync def run_canned_query(query_name: str) -&gt; QueryResult:\n    \"\"\"Run a pre-built query.\"\"\"\n    pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#apiknowledgepy-knowledge-management","title":"<code>api/knowledge.py</code> - Knowledge Management","text":"<pre><code>router = APIRouter(prefix=\"/knowledge\", tags=[\"knowledge\"])\n\n@router.get(\"/\")\nasync def get_knowledge() -&gt; KnowledgeBase:\n    \"\"\"Get all domain knowledge.\"\"\"\n    pass\n\n@router.get(\"/scoring\")\nasync def get_scoring_factors() -&gt; list[ScoringFactor]:\n    \"\"\"Get outcome scoring factors and weights.\"\"\"\n    pass\n\n@router.put(\"/scoring\")\nasync def update_scoring(factors: list[ScoringFactor]) -&gt; dict:\n    \"\"\"Update scoring factors (teach the system what's good).\"\"\"\n    pass\n\n@router.get(\"/rules\")\nasync def get_business_rules() -&gt; list[BusinessRule]:\n    \"\"\"Get business rules.\"\"\"\n    pass\n\n@router.post(\"/rules\")\nasync def add_rule(rule: BusinessRule) -&gt; dict:\n    \"\"\"Add a new business rule.\"\"\"\n    pass\n\n@router.get(\"/metrics\")\nasync def get_metrics() -&gt; list[MetricDefinition]:\n    \"\"\"Get metric definitions.\"\"\"\n    pass\n\n@router.post(\"/teach\")\nasync def teach(session: TeachingSession) -&gt; dict:\n    \"\"\"\n    Interactive teaching session.\n\n    User provides examples of good/bad outcomes,\n    system learns patterns.\n    \"\"\"\n    pass\n\n@router.post(\"/feedback\")\nasync def record_feedback(feedback: RecommendationFeedback) -&gt; dict:\n    \"\"\"\n    Record feedback on a recommendation.\n    Used to improve future suggestions.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#apiadminpy-administration","title":"<code>api/admin.py</code> - Administration","text":"<pre><code>router = APIRouter(prefix=\"/admin\", tags=[\"admin\"])\n\n@router.get(\"/health\")\nasync def health_check() -&gt; dict:\n    \"\"\"Health check endpoint.\"\"\"\n    return {\n        \"status\": \"running\",\n        \"template\": current_template,\n        \"tables\": len(get_tables()),\n        \"brain_connected\": check_brain_connection()\n    }\n\n@router.get(\"/templates\")\nasync def list_templates() -&gt; list[TemplateInfo]:\n    \"\"\"List available vertical templates.\"\"\"\n    pass\n\n@router.post(\"/templates/{template_name}/activate\")\nasync def activate_template(template_name: str) -&gt; dict:\n    \"\"\"Switch to a different vertical template.\"\"\"\n    pass\n\n@router.post(\"/export\")\nasync def export_config() -&gt; dict:\n    \"\"\"Export current configuration (for backup/migration).\"\"\"\n    pass\n\n@router.post(\"/import\")\nasync def import_config(config: dict) -&gt; dict:\n    \"\"\"Import configuration.\"\"\"\n    pass\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#server-entry-point-serverpy","title":"Server Entry Point (<code>server.py</code>)","text":"<pre><code>import uvicorn\nfrom fastapi import FastAPI\nfrom contextlib import asynccontextmanager\n\nfrom core.sql_engine import SQLEngine\nfrom core.vector_engine import VectorEngine\nfrom core.knowledge import KnowledgeManager\nfrom core.classifier import QuestionClassifier\nfrom core.orchestrator import IntelligenceOrchestrator\nfrom api import data, query, knowledge, admin\n\n# Configuration\nBRAIN_URL = \"http://localhost:8080\"\nTEMPLATE = \"dealership\"\nDB_PATH = \"./storage/databases/main.db\"\nVECTOR_PATH = \"./storage/vectors\"\nKNOWLEDGE_PATH = \"./storage/knowledge/knowledge.json\"\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"Initialize components on startup.\"\"\"\n    global orchestrator\n\n    # Initialize engines\n    sql_engine = SQLEngine(DB_PATH, BRAIN_URL)\n    vector_engine = VectorEngine(\"main\")\n    knowledge_mgr = KnowledgeManager(KNOWLEDGE_PATH)\n    classifier = QuestionClassifier(BRAIN_URL)\n\n    # Create orchestrator\n    orchestrator = IntelligenceOrchestrator(\n        sql_engine=sql_engine,\n        vector_engine=vector_engine,\n        knowledge=knowledge_mgr,\n        classifier=classifier,\n        brain_url=BRAIN_URL,\n        template=TEMPLATE\n    )\n\n    print(f\"Intelligence ready with template: {TEMPLATE}\")\n    yield\n\n    # Cleanup\n    sql_engine.close()\n\n\napp = FastAPI(\n    title=\"Nebulus Intelligence\",\n    version=\"0.1.0\",\n    lifespan=lifespan\n)\n\n# Register routers\napp.include_router(data.router)\napp.include_router(query.router)\napp.include_router(knowledge.router)\napp.include_router(admin.router)\n\n\n@app.get(\"/\")\ndef root():\n    return {\n        \"service\": \"nebulus-intelligence\",\n        \"status\": \"running\",\n        \"template\": TEMPLATE\n    }\n\n\ndef main():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8081)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#pm2-configuration-update","title":"PM2 Configuration Update","text":"<pre><code>{\n    \"apps\": [\n        {\n            \"name\": \"nebulus-brain\",\n            \"script\": \"./infrastructure/start_brain.sh\",\n            \"interpreter\": \"none\"\n        },\n        {\n            \"name\": \"nebulus-intelligence\",\n            \"script\": \"./infrastructure/start_intelligence.sh\",\n            \"interpreter\": \"none\"\n        }\n    ]\n}\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#integration-with-open-webui","title":"Integration with Open WebUI","text":""},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#option-a-custom-toolfunction","title":"Option A: Custom Tool/Function","text":"<p>Open WebUI supports custom tools. Create a tool that calls Intelligence API:</p> <pre><code># Tool definition for Open WebUI\n{\n    \"name\": \"query_business_data\",\n    \"description\": \"Query your business data with natural language\",\n    \"parameters\": {\n        \"question\": {\n            \"type\": \"string\",\n            \"description\": \"Your question about the data\"\n        }\n    }\n}\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#option-b-proxy-through-brain","title":"Option B: Proxy Through Brain","text":"<p>Add an endpoint in Brain that proxies to Intelligence:</p> <pre><code># In brain/server.py\n@app.post(\"/v1/intelligence/ask\")\nasync def intelligence_proxy(request: QuestionRequest):\n    async with httpx.AsyncClient() as client:\n        response = await client.post(\n            \"http://localhost:8081/query/ask\",\n            json=request.dict()\n        )\n        return response.json()\n</code></pre>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#option-c-direct-integration-nebulus-gantry","title":"Option C: Direct Integration (Nebulus Gantry)","text":"<p>When building Nebulus Gantry (custom UI), integrate Intelligence natively with dedicated data analysis views.</p>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#implementation-priority","title":"Implementation Priority","text":""},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#phase-1-foundation-week-1-2","title":"Phase 1: Foundation (Week 1-2)","text":"<ul> <li>[ ] Basic directory structure</li> <li>[ ] SQLite engine with text-to-SQL</li> <li>[ ] CSV ingestion</li> <li>[ ] Simple API endpoints</li> <li>[ ] Dealership template (config only)</li> </ul>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#phase-2-knowledge-layer-week-3-4","title":"Phase 2: Knowledge Layer (Week 3-4)","text":"<ul> <li>[ ] Knowledge manager</li> <li>[ ] Scoring system</li> <li>[ ] Business rules engine</li> <li>[ ] Teaching interface</li> </ul>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#phase-3-semantic-search-week-5-6","title":"Phase 3: Semantic Search (Week 5-6)","text":"<ul> <li>[ ] ChromaDB integration</li> <li>[ ] Embedding generation</li> <li>[ ] Similarity search</li> <li>[ ] Pattern detection</li> </ul>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#phase-4-orchestration-week-7-8","title":"Phase 4: Orchestration (Week 7-8)","text":"<ul> <li>[ ] Question classifier</li> <li>[ ] Full orchestrator</li> <li>[ ] Strategic analysis</li> <li>[ ] Response synthesis</li> </ul>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#phase-5-polish-week-9-10","title":"Phase 5: Polish (Week 9-10)","text":"<ul> <li>[ ] Open WebUI integration</li> <li>[ ] Additional templates</li> <li>[ ] Testing &amp; documentation</li> <li>[ ] Security hardening</li> </ul>"},{"location":"plans/2026-02-02-nebulus-intelligence-architecture/#open-questions","title":"Open Questions","text":"<ol> <li>Embedding model: Use Qwen via Brain, or dedicated embedding model?</li> <li>Multi-tenancy: One instance per customer, or multi-tenant?</li> <li>UI for knowledge capture: Build custom, or use Open WebUI chat?</li> <li>Data refresh: Manual re-upload, or watch folder/API push?</li> </ol>"}]}